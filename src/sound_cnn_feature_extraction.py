import msdi_io as msdi
from sklearn import svm
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.utils import shuffle
import tensorflow as tf
import numpy as np
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout
from keras.models import Sequential
SGD = tf.keras.optimizers.SGD

def get_model():
    model = Sequential()

    model.add(Conv2D(32, (4,3),activation="relu", strides=(1,1), padding = "same", input_shape=(500,12,1)))
    model.add(MaxPooling2D((4,2), strides=(4,2)))

    model.add(Conv2D(64, (4,3),activation="relu", strides=(1,1), padding = "same", input_shape=(500,12,1)))
    model.add(MaxPooling2D((4,2), strides=(4,2)))

    model.add(Conv2D(64, (4,3),activation="relu", strides=(1,1), padding = "same", input_shape=(500,12,1)))
    model.add(MaxPooling2D((4,1), strides=(4,1)))

    model.add(Conv2D(32, (1,1),activation="relu", strides=(1,1), padding = "same", input_shape=(500,12,1)))
    model.add(MaxPooling2D((4,3), strides=(4,3)))

    model.add(Flatten())
    model.add(Activation("sigmoid"))

    model.add(Dense(16,activation="relu"))
    model.add(Dense(15,activation="softmax"))

    model.summary()
    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])

    return model

def feature_extractor_processing(nbr_sample):
    _msdi_path = "./../data/"
    df = msdi.get_msdi_dataframe(_msdi_path)
    df = shuffle(df)

    list_index = df['genre'].drop_duplicates().tolist()

    datas=[]
    labels = []
    for i in range(min(len(df),nbr_sample)):
        data = msdi.load_mfcc(df.iloc[i], _msdi_path)
        data = data[:500]

        if len(data) < 500:
            continue

        datas.append(data)
        labels.append(list_index.index(df['genre'].tolist()[i]))

    datas = np.expand_dims(datas, axis=-1)
    labels = tf.keras.utils.to_categorical(labels)
    X_train, X_test, y_train, y_test = train_test_split(datas, labels, test_size=0.10, random_state=42)

    model = get_model()
    
    model.fit(tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train), batch_size=32, epochs=100, validation_data=(tf.convert_to_tensor(X_test), tf.convert_to_tensor(y_test))) 
    model.evaluate(X_test, y_test, batch_size=32)


if __name__ == "__main__":
    feature_extractor_processing(1000)
    